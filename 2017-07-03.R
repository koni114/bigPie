summary(iris)
x = table(iris$)
summary(iris)
x = table(iris$Species) #
View(x)
x1 <- -1
2 -> x2

x3 = 1:10 #array 1 to 10 save to x3
(x4 = c(1,5,3,9))
x4[2]
matrix(1:15, nrow = 5 ) # desinate row 5
matrix(1:15, ncol = 3 ) # desinate col 3
x5 = matrix(1:15, ncol = 3, byrow=T ) # we can fill the row 1, 2, 3..
x5 = matrix(1:15 ,ncol=3, byrow=T)
View(x5)
x5[2,1] # 행, 열, 면
x5[c(2,4), 3] # c 함수의 값을 불러올 수 도 있음. 내가 지정한 값의 반대값 --> - 붙이면 됨
              # matrix는 데이터 타입이 같아야함. --> 다양한 데이터 타입을 가져오려면 matrixFrame 이라고 함
str(iris) # matrixFrame


# 통계에 대해서 시작!
# 데이터에 대한 대표 수치들을 만들겠다. --> 예를들어 중앙값, 평균값 등등..! 보통 평균을 구하라고 하면 산술 평균을 구한다.
# but, 학점 값은 가중 평균을 사용(가중치에 대한 평균을 계산)

x1 = c(1,2,3,4,5,4,3,6,7, 1000)
sum(x1)/length(x1) # 평균
mean(x1) # 1000 이라는 이상치를 처리를 해주어야 함. 따라서 중앙값을 찾기도 한다.
((n/2)+((n/2)+1))/2
median(x1) # 중앙값을 구하는 함수
           # 만약 데이터가 정규 분포를 가지고 있다면, 중앙값과 평균값이 일치
           # 의사결정을 할때 데이터의 분산을 보면서 판단.

          # 만약 글자에 대한 평균을 어떻게 구할 것인가?
          # --> 평균을 만들 수 있는 근거가 있어야 한다.
          # ex) 빈도
          # 오버피팅 . 추정,
          # 흩어진 정도를 따질 때 --> x- xbar ex) 1, 3, 5


# 모집단 - 관심의 대상이 되는 모든 사람, 응답 결과, 실험 결과, 측정값들 전체의 집합
# 표본 - 모집단에서 일부 추출 --> 모집단을 대표하는 것. 극단적으로 추출하면 문제가 생김
# 전수조사, 표본조사, 임의추출(random sampling)

# 로또
sample(1:45, 6, replace = F ) # F면 복원을 하지 않겠다
ind = sample(1:nrow(iris), 150, replace = F) # 데이터를 섞은 다음 ind에 저장
A1 = iris[ind, ]
View(A1)
View(iris)


ind1 = sample(1:nrow(iris), nrow(iris)*0.7, replace= F ) #??
train=iris[ind1,]
test=iris[-ind1,]

#층화 추출 패키지는 별도로 설치해야 함
# 추측통계학, 기술통계학
# 시각화는 기술통계학의 한 분야

# 기술통계학 data
# summary(iris)
# min 최소값,
# 사분위 수 --> (이상 치들이 여기에 들어감. 나중에 일괄적으로 정리를 해야하는데, 제거하기 위해 분위 수를 사용)
# 중앙 값,
# 평균 값 -> 중앙 값과 비교
# 동일한 성향일수록 흩어진 정도가 적다.

# 시각화 방법
hist(iris$Petal.Length) #구간별로 빈도 수. 단절된 영역이 보임. --> 데이터가 그룹핑이 가능함을 추측 가능
boxplot(iris[,1:4]) # 검은선이 median,

# 반드시 분석에 들어가기 전에 전처리 단계가 필요

# y = a + bx

# 정규화!! OR 표준화
# scale 함수 --> 표준화 단위가 너무 차이가 나는 경우, 표준화 시켜주어야 함
A2 = iris
A2[,1:4] = scale(iris[,1:4])
View(A2)


# 양적자료, 질적자료
# factor와 numeric을 구분해야 함 factor는 단순히 그룹을 지정하기 위해 숫자를 지정한 것. --> 범주형 데이터
str(iris)
nlevels(iris$Species)
levels(iris$Species)
# 명목자료 -> 범주를 숫자로 대치 순서자료 -> 순서의 개념을 갖는 질적 자료 집단화 자료 -> 양적 자료를 구간별로 구분하여 범주형자료로 변환

# 도수분포표
library(MASS)
data("survey")
View(survey)
t1 = table(survey$Sex, survey$Smoke) #

prop.table(t1,1) # 전체 합계를 기준으로! 1은 행의 합이 1이 되도록, 2는 열단위.

# 막대 그래프
barplot(t1)

# 줄기- 잎 그래프
# 시계열 그래프


# 각각의 간격 구조를 알아야 함.
# 2장
# 모평균과 표본평균
# 알파벳으로 되어있는것이 표본에 대한 표기법이라고 생각하면 됨
# 잔차(편차)제곱합 , 최소제곱합
# 위의 값들을 왜 나오는가?
# 분류같은 경우는 얼마나 분류를 제대로 하는가,

plot(iris$Petal.Length, iris$Sepal.Length) #x축 y축에 대해서 절사 를 시켜주어야 한다
# 부동산 시세 --> 하나의 선으로 만들지 못하기 때문에 여러 모델을 구한다.

n = round((length(iris$Sepal.Length)*0.1)/2, 0)

x1 = sort(iris$Sepal.Length) # 반드시 정렬을 한 상태에서 절사를 시켜주어야 한다!!!!!!!!!!!!!!!!!!!
x2 = x1[(n+1):(length(iris$Sepal.Length)-n)]
str(x2)

# 중위수 : 정 중앙에 있는 값 (홀수, 짝수)
# ex) 메이저리그 연봉 문제.
# 데이터가 종모양 -> 아주 좋은 모양, but 한쪽으로 치우쳐저 있는 모양이면 좋지 않은 모양


# 최빈값
# 양적자료, 질적자료 다 가능

# 산포(흩어진정도)의 척도
# 분위수 범위 -> 좀더 이상적인 데이터들을 빼고, 어느정도 흩어져 있는지를 측정
# 얼마나 흩어져 있는지를 보는 것. 평균에 많이 모여있을수록 동일한 패턴이 존재할 확률이 높다는 것.
# 표준화 시킬 때 범위로 나누어 주는 경우도 존재
# 위치척도
# 반드시 소트가 되어 있어야 한다.

# 좋다, 나쁘다를 판단할 기준이 있어야 하는데,

hist(rnorm(100000, mean = 100, sd= 3)) # 데이터의 개수가 많아질수록 점점 좁아진다. 데이터를 인위적으로 만드는 방식
                                       # 만약 뒤에 mean과 sd를 지우면 평균이 0, 분산이1이 되는 것 -> Zi
# 데부분의 데이터는 -3 < z < 3 안에 놓인다. 시그마가 1이기 때문에


# 빅데이터를 할 때,변수가 많다고 해서 반드시 좋은 것은 아니다. 관계성을 찾아내려고 하는 것이기 때문에, 변수가 많아지면, 그 변수에 대해서 일일히 설명력을 가져아햔다.


# 상관 관계 분석
# 서로 연관성이 있는 것. -> 빅데이터에서 가장 중요하게 따지는 것.
# 우리가 상관관계가 나오게끔 유도를 해야 함.
# 어떻게 확인?
# 1. plot을 그려 확인 -> 직관적으로 이해 증가, 감소되는 경향을 보임. 중요한 것은 무조건 상관계수가 높은 것이 좋은 것이 아니라, 관계성이 존재하는지를  확인하는 것이 중요
# 2. 공분산 확인 -> 두 변수 사이의 관계에 대한 형태, 방향, 그리고 밀접관계의 강도 등을 알 수 있음.
# 0.6이상은 좋은 상관관계를 가진다고 보통 이야기 함

cor(iris[,1:4]) # 상관계수 확인
cor.test(iris$Sepal.Length, iris$Petal.Length) # 상관계수가 존재하는지를 검정
# 가설검정
# 텍스트 마이닝에서 빈도화를 어떻게 할 것인가?
#

